{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8107130d",
   "metadata": {},
   "source": [
    "## üìä Dataset Statistics\n",
    "\n",
    "| Dataset | Total | Normal | Abnormal |\n",
    "|---------|-------|--------|----------|\n",
    "| **NIH** | 112,120 | 60,361 (53.8%) | 51,759 (46.2%) |\n",
    "| **Pediatric** | 5,856 | 1,583 (27.0%) | 4,273 (73.0%) |\n",
    "| **CheXpert** | 29,031 | 1,123 (3.9%) | 27,908 (96.1%) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138fb6ef",
   "metadata": {
    "tags": [
     "display-tuning"
    ]
   },
   "outputs": [],
   "source": [
    "# Notebook display tweaks: compact code, scrollable outputs, clearer tables\n",
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ":root {\n",
    "  --code-font-size: 12px;\n",
    "  --input-max-height: 200px;\n",
    "  --output-font-size: 14px;\n",
    "  --output-max-height: 400px;\n",
    "  --output-line-height: 1.35;\n",
    "}\n",
    "div.cell.code_cell .input_area {\n",
    "  max-height: var(--input-max-height);\n",
    "  overflow: auto;\n",
    "  font-size: var(--code-font-size);\n",
    "}\n",
    "div.cell.code_cell .CodeMirror-lines {\n",
    "  font-size: var(--code-font-size);\n",
    "}\n",
    "div.output_wrapper, div.output {\n",
    "  font-size: var(--output-font-size);\n",
    "  line-height: var(--output-line-height);\n",
    "}\n",
    "div.output_subarea {\n",
    "  max-height: var(--output-max-height);\n",
    "  overflow: auto;\n",
    "}\n",
    "</style>\n",
    "\"\"\")\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 20)\n",
    "pd.set_option(\"display.max_columns\", 20)\n",
    "pd.set_option(\"display.width\", 120)\n",
    "pd.set_option(\"display.max_colwidth\", 120)\n",
    "pd.set_option(\"display.float_format\", \"{:.4f}\".format)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23beb31e",
   "metadata": {},
   "source": [
    "---\n",
    "# üîß Setup & Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8ba208a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Moataz CAS\\projectM3\\CAS-AML-M3-Project-AE\n",
      "Python version: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "# Check current working directory\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"Python version: {os.sys.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81a2c2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? processed: F:\\CAS AML\\M3_project\\downloads\\data\\processed\n",
      "? labels: F:\\CAS AML\\M3_project\\downloads\\data\\labels\n",
      "? scripts: F:\\CAS AML\\M3_project\\downloads\\scripts\n",
      "? Results: F:\\CAS AML\\M3_project\\downloads\\Results\n",
      "? models: F:\\CAS AML\\M3_project\\downloads\\models\n",
      "\n",
      "? Project root: F:\\CAS AML\\M3_project\\downloads\n",
      "? Data dir: F:\\CAS AML\\M3_project\\downloads\\data\\processed\n"
     ]
    }
   ],
   "source": [
    "# Define project paths (auto-detect repo root; override if needed)\n",
    "from pathlib import Path\n",
    "\n",
    "# Set to your data root if different from the current working directory\n",
    "OVERRIDE_PROJECT_ROOT = Path(r\"F:\\\\CAS AML\\\\M3_project\\\\downloads\")\n",
    "\n",
    "PROJECT_ROOT = Path(OVERRIDE_PROJECT_ROOT) if OVERRIDE_PROJECT_ROOT else Path.cwd()\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "LABELS_DIR = PROJECT_ROOT / \"data\" / \"labels\"\n",
    "SCRIPTS_DIR = PROJECT_ROOT / \"scripts\"\n",
    "RESULTS_DIR = PROJECT_ROOT / \"Results\"\n",
    "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
    "\n",
    "for directory in [DATA_DIR, LABELS_DIR, SCRIPTS_DIR, RESULTS_DIR, MODELS_DIR]:\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"? {directory.name}: {directory}\")\n",
    "\n",
    "import sys\n",
    "if str(SCRIPTS_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(SCRIPTS_DIR))\n",
    "\n",
    "print(f\"\\n? Project root: {PROJECT_ROOT}\")\n",
    "print(f\"? Data dir: {DATA_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10c6c29",
   "metadata": {},
   "source": [
    "### Import Libraries (Keras 3.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0182aead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Keras version: 3.12.0\n",
      "‚úÖ Keras backend: torch\n",
      "‚úÖ NumPy version: 1.26.4\n",
      "‚úÖ Pandas version: 2.3.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'torch'  # Options: 'torch', 'tensorflow', 'jax'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, balanced_accuracy_score,\n",
    "    classification_report, confusion_matrix, roc_curve\n",
    ")\n",
    "import h5py\n",
    "import keras\n",
    "from keras import layers, models, callbacks, optimizers\n",
    "import json\n",
    "from pathlib import Path\n",
    "import gc\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(f\"‚úÖ Keras version: {keras.__version__}\")\n",
    "print(f\"‚úÖ Keras backend: {keras.backend.backend()}\")\n",
    "print(f\"‚úÖ NumPy version: {np.__version__}\")\n",
    "print(f\"‚úÖ Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e36fc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "GPU: NVIDIA GeForce RTX 4060\n",
      "GPU memory: 8.0 GB\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "backend = keras.backend.backend()\n",
    "\n",
    "if backend == 'torch':\n",
    "    import torch\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA version: {torch.version.cuda}\")\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "elif backend == 'tensorflow':\n",
    "    import tensorflow as tf\n",
    "    print(f\"TensorFlow version: {tf.__version__}\")\n",
    "    print(f\"GPU devices: {tf.config.list_physical_devices('GPU')}\")\n",
    "elif backend == 'jax':\n",
    "    import jax\n",
    "    print(f\"JAX version: {jax.__version__}\")\n",
    "    print(f\"JAX devices: {jax.devices()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e50e1ac",
   "metadata": {},
   "source": [
    "---\n",
    "# üìÅ Phase 1: Baseline Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babd6854",
   "metadata": {},
   "source": [
    "## Phase 1a: All Data Comparison\n",
    "\n",
    "**Goal:** Quantify baseline distribution shift using all images (mixed pathologies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3ea086a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PHASE 1a: LOADING TEST DATA (ALL IMAGES)\n",
      "================================================================================\n",
      "\n",
      "üìÇ Loading nih...\n",
      "   Shape: (16655, 224, 224, 1)\n",
      "   Samples: 16,655\n",
      "   Memory: 3187.9 MB\n",
      "\n",
      "üìÇ Loading pediatric...\n",
      "   Shape: (879, 224, 224, 1)\n",
      "   Samples: 879\n",
      "   Memory: 168.2 MB\n",
      "\n",
      "üìÇ Loading chexpert...\n",
      "   Shape: (29031, 224, 224, 1)\n",
      "   Samples: 29,031\n",
      "   Memory: 5556.7 MB\n",
      "\n",
      "‚úÖ Loaded 3 datasets\n"
     ]
    }
   ],
   "source": [
    "# Load test images from all datasets\n",
    "print(\"=\"*80)\n",
    "print(\"PHASE 1a: LOADING TEST DATA (ALL IMAGES)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for dataset_name in ['nih', 'pediatric', 'chexpert']:\n",
    "    h5_path = DATA_DIR / dataset_name / 'test.h5'\n",
    "    \n",
    "    if not h5_path.exists():\n",
    "        print(f\"‚ö†Ô∏è  {dataset_name}: File not found - {h5_path}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nüìÇ Loading {dataset_name}...\")\n",
    "    \n",
    "    with h5py.File(h5_path, 'r') as f:\n",
    "        images = f['images'][:]\n",
    "        labels = f['labels'][:]\n",
    "        \n",
    "    datasets[dataset_name] = {\n",
    "        'images': images,\n",
    "        'labels': labels,\n",
    "        'n_samples': len(images)\n",
    "    }\n",
    "    \n",
    "    print(f\"   Shape: {images.shape}\")\n",
    "    print(f\"   Samples: {len(images):,}\")\n",
    "    print(f\"   Memory: {images.nbytes / 1024**2:.1f} MB\")\n",
    "\n",
    "print(f\"\\n‚úÖ Loaded {len(datasets)} datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2449d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPUTING PIXEL STATISTICS\n",
      "================================================================================\n",
      "\n",
      "NIH:\n",
      "  Mean:   -0.0042\n",
      "  Std:    0.4952\n",
      "  Range:  [-1.0000, 1.0000]\n",
      "  Median: 0.0431\n",
      "\n",
      "PEDIATRIC:\n",
      "  Mean:   -0.0416\n",
      "  Std:    0.4738\n",
      "  Range:  [-1.0000, 1.0000]\n",
      "  Median: 0.0431\n",
      "\n",
      "CHEXPERT:\n",
      "  Mean:   0.0127\n",
      "  Std:    0.5744\n",
      "  Range:  [-1.0000, 1.0000]\n",
      "  Median: 0.0196\n",
      "\n",
      "  Dataset      Mean      Std  Min  Max   Median       Q25      Q75\n",
      "      NIH -0.004235 0.495229 -1.0  1.0 0.043137 -0.349020 0.388235\n",
      "PEDIATRIC -0.041632 0.473798 -1.0  1.0 0.043137 -0.372549 0.349020\n",
      " CHEXPERT  0.012683 0.574401 -1.0  1.0 0.019608 -0.482353 0.505882\n"
     ]
    }
   ],
   "source": [
    "# Compute pixel statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPUTING PIXEL STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "stats_1a = []\n",
    "\n",
    "for name, data in datasets.items():\n",
    "    images = data['images']\n",
    "    \n",
    "    stat = {\n",
    "        'Dataset': name.upper(),\n",
    "        'Mean': images.mean(),\n",
    "        'Std': images.std(),\n",
    "        'Min': images.min(),\n",
    "        'Max': images.max(),\n",
    "        'Median': np.median(images),\n",
    "        'Q25': np.percentile(images, 25),\n",
    "        'Q75': np.percentile(images, 75)\n",
    "    }\n",
    "    stats_1a.append(stat)\n",
    "    \n",
    "    print(f\"\\n{name.upper()}:\")\n",
    "    print(f\"  Mean:   {stat['Mean']:.4f}\")\n",
    "    print(f\"  Std:    {stat['Std']:.4f}\")\n",
    "    print(f\"  Range:  [{stat['Min']:.4f}, {stat['Max']:.4f}]\")\n",
    "    print(f\"  Median: {stat['Median']:.4f}\")\n",
    "\n",
    "df_stats_1a = pd.DataFrame(stats_1a)\n",
    "print(\"\\n\" + df_stats_1a.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "039c38ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPUTING JENSEN-SHANNON DIVERGENCE\n",
      "================================================================================\n",
      "  NIH        vs PEDIATRIC : 0.1560\n",
      "  NIH        vs CHEXPERT  : 0.2140\n",
      "  PEDIATRIC  vs CHEXPERT  : 0.3089\n",
      "\n",
      "‚úÖ Results saved to F:\\CAS AML\\M3_project\\downloads\\Results\\phase1a\n"
     ]
    }
   ],
   "source": [
    "# Compute JS Divergence\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "def compute_js_divergence(images1, images2, bins=100):\n",
    "    \"\"\"Compute Jensen-Shannon divergence between two image distributions\"\"\"\n",
    "    hist1, _ = np.histogram(images1.flatten(), bins=bins, range=(0, 1), density=True)\n",
    "    hist2, _ = np.histogram(images2.flatten(), bins=bins, range=(0, 1), density=True)\n",
    "    \n",
    "    # Normalize to probability distributions\n",
    "    hist1 = hist1 / hist1.sum()\n",
    "    hist2 = hist2 / hist2.sum()\n",
    "    \n",
    "    return jensenshannon(hist1, hist2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPUTING JENSEN-SHANNON DIVERGENCE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "js_results_1a = []\n",
    "dataset_names = list(datasets.keys())\n",
    "\n",
    "for i, name1 in enumerate(dataset_names):\n",
    "    for name2 in dataset_names[i+1:]:\n",
    "        js_div = compute_js_divergence(\n",
    "            datasets[name1]['images'],\n",
    "            datasets[name2]['images']\n",
    "        )\n",
    "        \n",
    "        js_results_1a.append({\n",
    "            'Dataset1': name1.upper(),\n",
    "            'Dataset2': name2.upper(),\n",
    "            'JS_Divergence': js_div\n",
    "        })\n",
    "        \n",
    "        print(f\"  {name1.upper():10s} vs {name2.upper():10s}: {js_div:.4f}\")\n",
    "\n",
    "df_js_1a = pd.DataFrame(js_results_1a)\n",
    "\n",
    "# Save results\n",
    "phase1a_dir = RESULTS_DIR / 'phase1a'\n",
    "phase1a_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_stats_1a.to_csv(phase1a_dir / 'phase1a_statistics.csv', index=False)\n",
    "df_js_1a.to_csv(phase1a_dir / 'phase1a_js_divergence.csv', index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Results saved to {phase1a_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b9aba63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Visualization saved\n"
     ]
    }
   ],
   "source": [
    "# Visualize JS Divergence\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "comparisons = [f\"{row['Dataset1']} vs\\n{row['Dataset2']}\" for _, row in df_js_1a.iterrows()]\n",
    "values = df_js_1a['JS_Divergence'].values\n",
    "\n",
    "bars = ax.bar(comparisons, values, color=['#FF6B6B', '#4ECDC4', '#45B7D1'], alpha=0.8, edgecolor='black')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, val in zip(bars, values):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{val:.4f}',\n",
    "            ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "ax.set_ylabel('JS Divergence', fontsize=14, fontweight='bold')\n",
    "ax.set_title('Phase 1a: Distribution Shift (All Images)', fontsize=16, fontweight='bold', pad=20)\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "ax.set_ylim(0, max(values) * 1.2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(phase1a_dir / 'phase1a_js_divergence.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Visualization saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6576190d",
   "metadata": {},
   "source": [
    "## Phase 1b: Normals-Only Comparison\n",
    "\n",
    "**Goal:** Isolate institutional/demographic shift by controlling for pathology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d110744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PHASE 1b: LOADING NORMAL IMAGES ONLY\n",
      "================================================================================\n",
      "\n",
      "üìÇ Loading nih normals...\n",
      "   Shape: (8902, 224, 224, 1)\n",
      "   Samples: 8,902\n",
      "\n",
      "üìÇ Loading pediatric normals...\n",
      "   Shape: (238, 224, 224, 1)\n",
      "   Samples: 238\n",
      "\n",
      "üìÇ Loading chexpert normals...\n",
      "   Shape: (1123, 224, 224, 1)\n",
      "   Samples: 1,123\n",
      "\n",
      "‚úÖ Loaded 3 datasets (normals only)\n"
     ]
    }
   ],
   "source": [
    "# Load normal images only\n",
    "print(\"=\"*80)\n",
    "print(\"PHASE 1b: LOADING NORMAL IMAGES ONLY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "datasets_normal = {}\n",
    "\n",
    "for dataset_name in ['nih', 'pediatric', 'chexpert']:\n",
    "    h5_path = DATA_DIR / dataset_name / 'test_normals.h5'\n",
    "    \n",
    "    if not h5_path.exists():\n",
    "        print(f\"‚ö†Ô∏è  {dataset_name}: File not found - {h5_path}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nüìÇ Loading {dataset_name} normals...\")\n",
    "    \n",
    "    with h5py.File(h5_path, 'r') as f:\n",
    "        images = f['images'][:]\n",
    "        labels = f['labels'][:]\n",
    "        \n",
    "    datasets_normal[dataset_name] = {\n",
    "        'images': images,\n",
    "        'labels': labels,\n",
    "        'n_samples': len(images)\n",
    "    }\n",
    "    \n",
    "    print(f\"   Shape: {images.shape}\")\n",
    "    print(f\"   Samples: {len(images):,}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Loaded {len(datasets_normal)} datasets (normals only)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02b26350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPUTING STATISTICS FOR NORMALS\n",
      "================================================================================\n",
      "  NIH        vs PEDIATRIC : 0.1031\n",
      "  NIH        vs CHEXPERT  : 0.2101\n",
      "  PEDIATRIC  vs CHEXPERT  : 0.2669\n",
      "\n",
      "‚úÖ Results saved to F:\\CAS AML\\M3_project\\downloads\\Results\\phase1b\n"
     ]
    }
   ],
   "source": [
    "# Compute statistics and JS divergence for normals\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPUTING STATISTICS FOR NORMALS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "stats_1b = []\n",
    "js_results_1b = []\n",
    "\n",
    "# Statistics\n",
    "for name, data in datasets_normal.items():\n",
    "    images = data['images']\n",
    "    stat = {\n",
    "        'Dataset': name.upper(),\n",
    "        'Mean': images.mean(),\n",
    "        'Std': images.std(),\n",
    "        'Min': images.min(),\n",
    "        'Max': images.max(),\n",
    "        'Median': np.median(images)\n",
    "    }\n",
    "    stats_1b.append(stat)\n",
    "\n",
    "# JS Divergence\n",
    "dataset_names = list(datasets_normal.keys())\n",
    "for i, name1 in enumerate(dataset_names):\n",
    "    for name2 in dataset_names[i+1:]:\n",
    "        js_div = compute_js_divergence(\n",
    "            datasets_normal[name1]['images'],\n",
    "            datasets_normal[name2]['images']\n",
    "        )\n",
    "        \n",
    "        js_results_1b.append({\n",
    "            'Dataset1': name1.upper(),\n",
    "            'Dataset2': name2.upper(),\n",
    "            'JS_Divergence': js_div\n",
    "        })\n",
    "        \n",
    "        print(f\"  {name1.upper():10s} vs {name2.upper():10s}: {js_div:.4f}\")\n",
    "\n",
    "df_stats_1b = pd.DataFrame(stats_1b)\n",
    "df_js_1b = pd.DataFrame(js_results_1b)\n",
    "\n",
    "# Save results\n",
    "phase1b_dir = RESULTS_DIR / 'phase1b'\n",
    "phase1b_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_stats_1b.to_csv(phase1b_dir / 'phase1b_statistics.csv', index=False)\n",
    "df_js_1b.to_csv(phase1b_dir / 'phase1b_js_divergence.csv', index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Results saved to {phase1b_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32362373",
   "metadata": {},
   "source": [
    "---\n",
    "# üìÅ Phase 2: Autoencoder Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec152a8",
   "metadata": {},
   "source": [
    "## Phase 2a: NIH_Full Autoencoder\n",
    "\n",
    "**Data:** All NIH images (normals + abnormals)  \n",
    "**Architecture:** Convolutional autoencoder with 256-dim latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "413308e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building autoencoder architecture...\n",
      "\n",
      "================================================================================\n",
      "ENCODER ARCHITECTURE\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"encoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"encoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ encoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ enc_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ enc_pool1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)        ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ enc_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   ‚îÇ        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ enc_pool2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)        ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ enc_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    ‚îÇ        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ enc_pool3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)        ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ enc_conv4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    ‚îÇ       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ enc_pool4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)        ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ enc_flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50176</span>)          ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ latent (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            ‚îÇ    <span style=\"color: #00af00; text-decoration-color: #00af00\">12,845,312</span> ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ encoder_input (\u001b[38;5;33mInputLayer\u001b[0m)      ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m1\u001b[0m)    ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ enc_conv1 (\u001b[38;5;33mConv2D\u001b[0m)              ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   ‚îÇ           \u001b[38;5;34m320\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ enc_pool1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)        ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ enc_conv2 (\u001b[38;5;33mConv2D\u001b[0m)              ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   ‚îÇ        \u001b[38;5;34m18,496\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ enc_pool2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)        ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ enc_conv3 (\u001b[38;5;33mConv2D\u001b[0m)              ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    ‚îÇ        \u001b[38;5;34m73,856\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ enc_pool3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)        ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ enc_conv4 (\u001b[38;5;33mConv2D\u001b[0m)              ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    ‚îÇ       \u001b[38;5;34m295,168\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ enc_pool4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)        ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ enc_flatten (\u001b[38;5;33mFlatten\u001b[0m)           ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50176\u001b[0m)          ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ latent (\u001b[38;5;33mDense\u001b[0m)                  ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            ‚îÇ    \u001b[38;5;34m12,845,312\u001b[0m ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,233,152</span> (50.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,233,152\u001b[0m (50.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,233,152</span> (50.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,233,152\u001b[0m (50.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DECODER ARCHITECTURE\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"decoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"decoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ decoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dec_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50176</span>)          ‚îÇ    <span style=\"color: #00af00; text-decoration-color: #00af00\">12,895,232</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dec_reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dec_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)     ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    ‚îÇ       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dec_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)     ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     ‚îÇ        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dec_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)     ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   ‚îÇ        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dec_conv4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)     ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,624</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ decoder_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">145</span> ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ decoder_input (\u001b[38;5;33mInputLayer\u001b[0m)      ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dec_dense (\u001b[38;5;33mDense\u001b[0m)               ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50176\u001b[0m)          ‚îÇ    \u001b[38;5;34m12,895,232\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dec_reshape (\u001b[38;5;33mReshape\u001b[0m)           ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dec_conv1 (\u001b[38;5;33mConv2DTranspose\u001b[0m)     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    ‚îÇ       \u001b[38;5;34m295,040\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dec_conv2 (\u001b[38;5;33mConv2DTranspose\u001b[0m)     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     ‚îÇ        \u001b[38;5;34m73,792\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dec_conv3 (\u001b[38;5;33mConv2DTranspose\u001b[0m)     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   ‚îÇ        \u001b[38;5;34m18,464\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dec_conv4 (\u001b[38;5;33mConv2DTranspose\u001b[0m)     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m16\u001b[0m)   ‚îÇ         \u001b[38;5;34m4,624\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ decoder_output (\u001b[38;5;33mConv2D\u001b[0m)         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m1\u001b[0m)    ‚îÇ           \u001b[38;5;34m145\u001b[0m ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,287,297</span> (50.69 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,287,297\u001b[0m (50.69 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,287,297</span> (50.69 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,287,297\u001b[0m (50.69 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "AUTOENCODER ARCHITECTURE\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"autoencoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ autoencoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            ‚îÇ    <span style=\"color: #00af00; text-decoration-color: #00af00\">13,233,152</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    ‚îÇ    <span style=\"color: #00af00; text-decoration-color: #00af00\">13,287,297</span> ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ autoencoder_input (\u001b[38;5;33mInputLayer\u001b[0m)  ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m1\u001b[0m)    ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ encoder (\u001b[38;5;33mFunctional\u001b[0m)            ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            ‚îÇ    \u001b[38;5;34m13,233,152\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ decoder (\u001b[38;5;33mFunctional\u001b[0m)            ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m1\u001b[0m)    ‚îÇ    \u001b[38;5;34m13,287,297\u001b[0m ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,520,449</span> (101.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m26,520,449\u001b[0m (101.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,520,449</span> (101.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m26,520,449\u001b[0m (101.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build autoencoder architecture\n",
    "def build_autoencoder(input_shape=(224, 224, 1), latent_dim=256):\n",
    "    \"\"\"\n",
    "    Build convolutional autoencoder\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Input image shape\n",
    "        latent_dim: Latent space dimension\n",
    "        \n",
    "    Returns:\n",
    "        encoder, decoder, autoencoder models\n",
    "    \"\"\"\n",
    "    \n",
    "    # ENCODER\n",
    "    encoder_input = layers.Input(shape=input_shape, name='encoder_input')\n",
    "    \n",
    "    x = layers.Conv2D(32, 3, activation='relu', padding='same', name='enc_conv1')(encoder_input)\n",
    "    x = layers.MaxPooling2D(2, padding='same', name='enc_pool1')(x)\n",
    "    \n",
    "    x = layers.Conv2D(64, 3, activation='relu', padding='same', name='enc_conv2')(x)\n",
    "    x = layers.MaxPooling2D(2, padding='same', name='enc_pool2')(x)\n",
    "    \n",
    "    x = layers.Conv2D(128, 3, activation='relu', padding='same', name='enc_conv3')(x)\n",
    "    x = layers.MaxPooling2D(2, padding='same', name='enc_pool3')(x)\n",
    "    \n",
    "    x = layers.Conv2D(256, 3, activation='relu', padding='same', name='enc_conv4')(x)\n",
    "    x = layers.MaxPooling2D(2, padding='same', name='enc_pool4')(x)\n",
    "    \n",
    "    x = layers.Flatten(name='enc_flatten')(x)\n",
    "    encoder_output = layers.Dense(latent_dim, activation='relu', name='latent')(x)\n",
    "    \n",
    "    encoder = models.Model(encoder_input, encoder_output, name='encoder')\n",
    "    \n",
    "    # DECODER\n",
    "    decoder_input = layers.Input(shape=(latent_dim,), name='decoder_input')\n",
    "    \n",
    "    x = layers.Dense(14 * 14 * 256, activation='relu', name='dec_dense')(decoder_input)\n",
    "    x = layers.Reshape((14, 14, 256), name='dec_reshape')(x)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(128, 3, activation='relu', strides=2, padding='same', name='dec_conv1')(x)\n",
    "    x = layers.Conv2DTranspose(64, 3, activation='relu', strides=2, padding='same', name='dec_conv2')(x)\n",
    "    x = layers.Conv2DTranspose(32, 3, activation='relu', strides=2, padding='same', name='dec_conv3')(x)\n",
    "    x = layers.Conv2DTranspose(16, 3, activation='relu', strides=2, padding='same', name='dec_conv4')(x)\n",
    "    \n",
    "    decoder_output = layers.Conv2D(1, 3, activation='sigmoid', padding='same', name='decoder_output')(x)\n",
    "    \n",
    "    decoder = models.Model(decoder_input, decoder_output, name='decoder')\n",
    "    \n",
    "    # AUTOENCODER\n",
    "    autoencoder_input = layers.Input(shape=input_shape, name='autoencoder_input')\n",
    "    encoded = encoder(autoencoder_input)\n",
    "    decoded = decoder(encoded)\n",
    "    autoencoder = models.Model(autoencoder_input, decoded, name='autoencoder')\n",
    "    \n",
    "    return encoder, decoder, autoencoder\n",
    "\n",
    "# Build models\n",
    "print(\"Building autoencoder architecture...\")\n",
    "encoder_2a, decoder_2a, autoencoder_2a = build_autoencoder()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ENCODER ARCHITECTURE\")\n",
    "print(\"=\"*80)\n",
    "encoder_2a.summary()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DECODER ARCHITECTURE\")\n",
    "print(\"=\"*80)\n",
    "decoder_2a.summary()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AUTOENCODER ARCHITECTURE\")\n",
    "print(\"=\"*80)\n",
    "autoencoder_2a.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de90db49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOADING NIH TRAINING DATA (ALL IMAGES)\n",
      "================================================================================\n",
      "‚úÖ Training: (78708, 224, 224, 1)\n",
      "‚úÖ Validation: (16757, 224, 224, 1)\n",
      "\n",
      "Training memory: 14.71 GB\n",
      "Validation memory: 3.13 GB\n"
     ]
    }
   ],
   "source": [
    "# Load NIH training data\n",
    "print(\"=\"*80)\n",
    "print(\"LOADING NIH TRAINING DATA (ALL IMAGES)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load train and validation\n",
    "train_path = DATA_DIR / 'nih' / 'train.h5'\n",
    "val_path = DATA_DIR / 'nih' / 'val.h5'\n",
    "\n",
    "with h5py.File(train_path, 'r') as f:\n",
    "    X_train = f['images'][:]\n",
    "    print(f\"‚úÖ Training: {X_train.shape}\")\n",
    "\n",
    "with h5py.File(val_path, 'r') as f:\n",
    "    X_val = f['images'][:]\n",
    "    print(f\"‚úÖ Validation: {X_val.shape}\")\n",
    "\n",
    "# Normalize to [0, 1] if needed\n",
    "if X_train.max() > 1.0:\n",
    "    X_train = X_train / 255.0\n",
    "    X_val = X_val / 255.0\n",
    "    print(\"‚úÖ Normalized to [0, 1]\")\n",
    "\n",
    "print(f\"\\nTraining memory: {X_train.nbytes / 1024**3:.2f} GB\")\n",
    "print(f\"Validation memory: {X_val.nbytes / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea2ad09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPILING AND TRAINING AUTOENCODER (PHASE 2a)\n",
      "================================================================================\n",
      "\n",
      "Starting training...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\common\\backend_utils.py:91: UserWarning: You might experience inconsistencies across backends when calling conv transpose with kernel_size=3, stride=2, dilation_rate=1, padding=same, output_padding=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.1771 - mae: 0.2906\n",
      "Epoch 1: val_loss improved from None to 0.14023, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 121ms/step - loss: 0.1526 - mae: 0.2572 - val_loss: 0.1402 - val_mae: 0.2359 - learning_rate: 0.0010\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\common\\backend_utils.py:91: UserWarning: You might experience inconsistencies across backends when calling conv transpose with kernel_size=3, stride=2, dilation_rate=1, padding=same, output_padding=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.1435 - mae: 0.2386\n",
      "Epoch 2: val_loss improved from 0.14023 to 0.13946, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 125ms/step - loss: 0.1429 - mae: 0.2373 - val_loss: 0.1395 - val_mae: 0.2324 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.1425 - mae: 0.2353\n",
      "Epoch 3: val_loss improved from 0.13946 to 0.13902, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 126ms/step - loss: 0.1424 - mae: 0.2349 - val_loss: 0.1390 - val_mae: 0.2307 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1420 - mae: 0.2336\n",
      "Epoch 4: val_loss improved from 0.13902 to 0.13889, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 127ms/step - loss: 0.1421 - mae: 0.2336 - val_loss: 0.1389 - val_mae: 0.2301 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1417 - mae: 0.2326\n",
      "Epoch 5: val_loss improved from 0.13889 to 0.13866, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 126ms/step - loss: 0.1419 - mae: 0.2328 - val_loss: 0.1387 - val_mae: 0.2291 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1415 - mae: 0.2318\n",
      "Epoch 6: val_loss improved from 0.13866 to 0.13859, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 126ms/step - loss: 0.1418 - mae: 0.2321 - val_loss: 0.1386 - val_mae: 0.2286 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1419 - mae: 0.2318\n",
      "Epoch 7: val_loss improved from 0.13859 to 0.13849, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 126ms/step - loss: 0.1417 - mae: 0.2316 - val_loss: 0.1385 - val_mae: 0.2280 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1418 - mae: 0.2313\n",
      "Epoch 8: val_loss improved from 0.13849 to 0.13836, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 126ms/step - loss: 0.1415 - mae: 0.2310 - val_loss: 0.1384 - val_mae: 0.2274 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1416 - mae: 0.2309\n",
      "Epoch 9: val_loss did not improve from 0.13836\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 122ms/step - loss: 0.1415 - mae: 0.2306 - val_loss: 0.1384 - val_mae: 0.2279 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1415 - mae: 0.2304\n",
      "Epoch 10: val_loss improved from 0.13836 to 0.13827, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 127ms/step - loss: 0.1414 - mae: 0.2303 - val_loss: 0.1383 - val_mae: 0.2269 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.1415 - mae: 0.2302\n",
      "Epoch 11: val_loss improved from 0.13827 to 0.13820, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 128ms/step - loss: 0.1413 - mae: 0.2299 - val_loss: 0.1382 - val_mae: 0.2266 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.1412 - mae: 0.2294\n",
      "Epoch 12: val_loss improved from 0.13820 to 0.13811, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 127ms/step - loss: 0.1413 - mae: 0.2295 - val_loss: 0.1381 - val_mae: 0.2260 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.1414 - mae: 0.2294\n",
      "Epoch 13: val_loss improved from 0.13811 to 0.13806, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 126ms/step - loss: 0.1412 - mae: 0.2292 - val_loss: 0.1381 - val_mae: 0.2259 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.1412 - mae: 0.2290\n",
      "Epoch 14: val_loss improved from 0.13806 to 0.13802, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 128ms/step - loss: 0.1411 - mae: 0.2289 - val_loss: 0.1380 - val_mae: 0.2256 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.1410 - mae: 0.2287\n",
      "Epoch 15: val_loss improved from 0.13802 to 0.13798, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 128ms/step - loss: 0.1411 - mae: 0.2287 - val_loss: 0.1380 - val_mae: 0.2254 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1411 - mae: 0.2286\n",
      "Epoch 16: val_loss improved from 0.13798 to 0.13796, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 126ms/step - loss: 0.1411 - mae: 0.2285 - val_loss: 0.1380 - val_mae: 0.2253 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1413 - mae: 0.2287\n",
      "Epoch 17: val_loss improved from 0.13796 to 0.13792, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 126ms/step - loss: 0.1410 - mae: 0.2283 - val_loss: 0.1379 - val_mae: 0.2251 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1411 - mae: 0.2283\n",
      "Epoch 18: val_loss did not improve from 0.13792\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 122ms/step - loss: 0.1410 - mae: 0.2282 - val_loss: 0.1379 - val_mae: 0.2252 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.1405 - mae: 0.2275\n",
      "Epoch 19: val_loss improved from 0.13792 to 0.13788, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 126ms/step - loss: 0.1410 - mae: 0.2280 - val_loss: 0.1379 - val_mae: 0.2248 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1404 - mae: 0.2273\n",
      "Epoch 20: val_loss improved from 0.13788 to 0.13786, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 126ms/step - loss: 0.1410 - mae: 0.2279 - val_loss: 0.1379 - val_mae: 0.2248 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1414 - mae: 0.2284\n",
      "Epoch 21: val_loss did not improve from 0.13786\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 122ms/step - loss: 0.1409 - mae: 0.2278 - val_loss: 0.1379 - val_mae: 0.2252 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1409 - mae: 0.2276\n",
      "Epoch 22: val_loss improved from 0.13786 to 0.13784, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 126ms/step - loss: 0.1409 - mae: 0.2277 - val_loss: 0.1378 - val_mae: 0.2247 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1408 - mae: 0.2269\n",
      "Epoch 23: val_loss improved from 0.13784 to 0.13775, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 126ms/step - loss: 0.1408 - mae: 0.2270 - val_loss: 0.1378 - val_mae: 0.2241 - learning_rate: 5.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1413 - mae: 0.2276\n",
      "Epoch 24: val_loss improved from 0.13775 to 0.13774, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 126ms/step - loss: 0.1408 - mae: 0.2270 - val_loss: 0.1377 - val_mae: 0.2241 - learning_rate: 5.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1409 - mae: 0.2271\n",
      "Epoch 25: val_loss improved from 0.13774 to 0.13774, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 126ms/step - loss: 0.1408 - mae: 0.2269 - val_loss: 0.1377 - val_mae: 0.2240 - learning_rate: 5.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.1408 - mae: 0.2270\n",
      "Epoch 26: val_loss improved from 0.13774 to 0.13772, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 126ms/step - loss: 0.1408 - mae: 0.2269 - val_loss: 0.1377 - val_mae: 0.2239 - learning_rate: 5.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.1407 - mae: 0.2267\n",
      "Epoch 27: val_loss did not improve from 0.13772\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 122ms/step - loss: 0.1408 - mae: 0.2268 - val_loss: 0.1377 - val_mae: 0.2239 - learning_rate: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1411 - mae: 0.2273\n",
      "Epoch 28: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 122ms/step - loss: 0.1408 - mae: 0.2268 - val_loss: 0.1377 - val_mae: 0.2239 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.1408 - mae: 0.2266\n",
      "Epoch 29: val_loss improved from 0.13772 to 0.13768, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 126ms/step - loss: 0.1407 - mae: 0.2265 - val_loss: 0.1377 - val_mae: 0.2236 - learning_rate: 2.5000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1405 - mae: 0.2263\n",
      "Epoch 30: val_loss improved from 0.13768 to 0.13768, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 126ms/step - loss: 0.1407 - mae: 0.2264 - val_loss: 0.1377 - val_mae: 0.2236 - learning_rate: 2.5000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.1402 - mae: 0.2258\n",
      "Epoch 31: val_loss improved from 0.13768 to 0.13768, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 126ms/step - loss: 0.1407 - mae: 0.2264 - val_loss: 0.1377 - val_mae: 0.2236 - learning_rate: 2.5000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.1408 - mae: 0.2266\n",
      "Epoch 32: val_loss improved from 0.13768 to 0.13767, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 126ms/step - loss: 0.1407 - mae: 0.2264 - val_loss: 0.1377 - val_mae: 0.2235 - learning_rate: 2.5000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1407 - mae: 0.2263\n",
      "Epoch 33: val_loss did not improve from 0.13767\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 122ms/step - loss: 0.1407 - mae: 0.2263 - val_loss: 0.1377 - val_mae: 0.2236 - learning_rate: 2.5000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.1406 - mae: 0.2261\n",
      "Epoch 34: val_loss improved from 0.13767 to 0.13766, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 126ms/step - loss: 0.1407 - mae: 0.2262 - val_loss: 0.1377 - val_mae: 0.2235 - learning_rate: 1.2500e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1410 - mae: 0.2266\n",
      "Epoch 35: val_loss improved from 0.13766 to 0.13766, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 126ms/step - loss: 0.1407 - mae: 0.2262 - val_loss: 0.1377 - val_mae: 0.2234 - learning_rate: 1.2500e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.1411 - mae: 0.2266\n",
      "Epoch 36: val_loss improved from 0.13766 to 0.13765, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 126ms/step - loss: 0.1407 - mae: 0.2262 - val_loss: 0.1377 - val_mae: 0.2234 - learning_rate: 1.2500e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1407 - mae: 0.2262\n",
      "Epoch 37: val_loss improved from 0.13765 to 0.13765, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 126ms/step - loss: 0.1407 - mae: 0.2262 - val_loss: 0.1377 - val_mae: 0.2234 - learning_rate: 1.2500e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1405 - mae: 0.2261\n",
      "Epoch 38: val_loss improved from 0.13765 to 0.13765, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 126ms/step - loss: 0.1407 - mae: 0.2261 - val_loss: 0.1377 - val_mae: 0.2234 - learning_rate: 1.2500e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1409 - mae: 0.2264\n",
      "Epoch 39: val_loss improved from 0.13765 to 0.13765, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 126ms/step - loss: 0.1406 - mae: 0.2261 - val_loss: 0.1376 - val_mae: 0.2234 - learning_rate: 6.2500e-05\n",
      "Epoch 40/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.1404 - mae: 0.2258\n",
      "Epoch 40: val_loss did not improve from 0.13765\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 122ms/step - loss: 0.1406 - mae: 0.2261 - val_loss: 0.1376 - val_mae: 0.2234 - learning_rate: 6.2500e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1400 - mae: 0.2253\n",
      "Epoch 41: val_loss improved from 0.13765 to 0.13765, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 126ms/step - loss: 0.1406 - mae: 0.2261 - val_loss: 0.1376 - val_mae: 0.2234 - learning_rate: 6.2500e-05\n",
      "Epoch 42/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1405 - mae: 0.2258\n",
      "Epoch 42: val_loss improved from 0.13765 to 0.13764, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 126ms/step - loss: 0.1406 - mae: 0.2261 - val_loss: 0.1376 - val_mae: 0.2234 - learning_rate: 6.2500e-05\n",
      "Epoch 43/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1412 - mae: 0.2268\n",
      "Epoch 43: val_loss improved from 0.13764 to 0.13764, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 127ms/step - loss: 0.1406 - mae: 0.2260 - val_loss: 0.1376 - val_mae: 0.2234 - learning_rate: 6.2500e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1400 - mae: 0.2252\n",
      "Epoch 44: val_loss did not improve from 0.13764\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 122ms/step - loss: 0.1406 - mae: 0.2260 - val_loss: 0.1376 - val_mae: 0.2234 - learning_rate: 6.2500e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1408 - mae: 0.2261\n",
      "Epoch 45: val_loss improved from 0.13764 to 0.13764, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 126ms/step - loss: 0.1406 - mae: 0.2260 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 3.1250e-05\n",
      "Epoch 46/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1407 - mae: 0.2261\n",
      "Epoch 46: val_loss improved from 0.13764 to 0.13764, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 127ms/step - loss: 0.1406 - mae: 0.2260 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 3.1250e-05\n",
      "Epoch 47/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1404 - mae: 0.2257\n",
      "Epoch 47: val_loss improved from 0.13764 to 0.13764, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 126ms/step - loss: 0.1406 - mae: 0.2260 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 3.1250e-05\n",
      "Epoch 48/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1404 - mae: 0.2257\n",
      "Epoch 48: val_loss did not improve from 0.13764\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 122ms/step - loss: 0.1406 - mae: 0.2260 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 3.1250e-05\n",
      "Epoch 49/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1404 - mae: 0.2256\n",
      "Epoch 49: val_loss improved from 0.13764 to 0.13764, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 126ms/step - loss: 0.1406 - mae: 0.2260 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 3.1250e-05\n",
      "Epoch 50/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1404 - mae: 0.2257\n",
      "Epoch 50: val_loss improved from 0.13764 to 0.13764, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 127ms/step - loss: 0.1406 - mae: 0.2260 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 1.5625e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1406 - mae: 0.2260\n",
      "Epoch 51: val_loss did not improve from 0.13764\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 122ms/step - loss: 0.1406 - mae: 0.2260 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 1.5625e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1409 - mae: 0.2263\n",
      "Epoch 52: val_loss did not improve from 0.13764\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 122ms/step - loss: 0.1406 - mae: 0.2260 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 1.5625e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1409 - mae: 0.2262\n",
      "Epoch 53: val_loss did not improve from 0.13764\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 122ms/step - loss: 0.1406 - mae: 0.2260 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 1.5625e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1405 - mae: 0.2259\n",
      "Epoch 54: val_loss did not improve from 0.13764\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 122ms/step - loss: 0.1406 - mae: 0.2260 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 1.5625e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1407 - mae: 0.2259\n",
      "Epoch 55: val_loss improved from 0.13764 to 0.13764, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 126ms/step - loss: 0.1406 - mae: 0.2260 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 7.8125e-06\n",
      "Epoch 56/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1409 - mae: 0.2263\n",
      "Epoch 56: val_loss improved from 0.13764 to 0.13764, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 127ms/step - loss: 0.1406 - mae: 0.2260 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 7.8125e-06\n",
      "Epoch 57/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.1409 - mae: 0.2263\n",
      "Epoch 57: val_loss did not improve from 0.13764\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 119ms/step - loss: 0.1406 - mae: 0.2260 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 7.8125e-06\n",
      "Epoch 58/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.1404 - mae: 0.2257\n",
      "Epoch 58: val_loss improved from 0.13764 to 0.13764, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 122ms/step - loss: 0.1406 - mae: 0.2260 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 7.8125e-06\n",
      "Epoch 59/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.1407 - mae: 0.2260\n",
      "Epoch 59: val_loss improved from 0.13764 to 0.13764, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 122ms/step - loss: 0.1406 - mae: 0.2260 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 7.8125e-06\n",
      "Epoch 60/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.1406 - mae: 0.2258\n",
      "Epoch 60: val_loss improved from 0.13764 to 0.13764, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 122ms/step - loss: 0.1406 - mae: 0.2260 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 3.9063e-06\n",
      "Epoch 61/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.1405 - mae: 0.2256\n",
      "Epoch 61: val_loss did not improve from 0.13764\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 118ms/step - loss: 0.1406 - mae: 0.2260 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 3.9063e-06\n",
      "Epoch 62/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.1405 - mae: 0.2257\n",
      "Epoch 62: val_loss improved from 0.13764 to 0.13764, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 122ms/step - loss: 0.1406 - mae: 0.2260 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 3.9063e-06\n",
      "Epoch 63/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.1406 - mae: 0.2260\n",
      "Epoch 63: val_loss did not improve from 0.13764\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 118ms/step - loss: 0.1406 - mae: 0.2259 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 3.9063e-06\n",
      "Epoch 64/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.1407 - mae: 0.2262\n",
      "Epoch 64: val_loss improved from 0.13764 to 0.13764, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 122ms/step - loss: 0.1406 - mae: 0.2259 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 3.9063e-06\n",
      "Epoch 65/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.1411 - mae: 0.2264\n",
      "Epoch 65: val_loss did not improve from 0.13764\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 118ms/step - loss: 0.1406 - mae: 0.2259 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 1.9531e-06\n",
      "Epoch 66/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.1405 - mae: 0.2258\n",
      "Epoch 66: val_loss did not improve from 0.13764\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 118ms/step - loss: 0.1406 - mae: 0.2259 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 1.9531e-06\n",
      "Epoch 67/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.1404 - mae: 0.2257\n",
      "Epoch 67: val_loss did not improve from 0.13764\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 118ms/step - loss: 0.1406 - mae: 0.2259 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 1.9531e-06\n",
      "Epoch 68/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.1406 - mae: 0.2260\n",
      "Epoch 68: val_loss did not improve from 0.13764\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 118ms/step - loss: 0.1406 - mae: 0.2259 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 1.9531e-06\n",
      "Epoch 69/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.1407 - mae: 0.2260\n",
      "Epoch 69: val_loss improved from 0.13764 to 0.13764, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 122ms/step - loss: 0.1406 - mae: 0.2259 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 1.9531e-06\n",
      "Epoch 70/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.1408 - mae: 0.2260\n",
      "Epoch 70: val_loss did not improve from 0.13764\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 119ms/step - loss: 0.1406 - mae: 0.2259 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 9.7656e-07\n",
      "Epoch 71/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.1405 - mae: 0.2257\n",
      "Epoch 71: val_loss improved from 0.13764 to 0.13764, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 121ms/step - loss: 0.1406 - mae: 0.2259 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 9.7656e-07\n",
      "Epoch 72/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.1404 - mae: 0.2257\n",
      "Epoch 72: val_loss did not improve from 0.13764\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 118ms/step - loss: 0.1406 - mae: 0.2259 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 9.7656e-07\n",
      "Epoch 73/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.1408 - mae: 0.2261\n",
      "Epoch 73: val_loss did not improve from 0.13764\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 118ms/step - loss: 0.1406 - mae: 0.2259 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 9.7656e-07\n",
      "Epoch 74/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.1404 - mae: 0.2256\n",
      "Epoch 74: val_loss did not improve from 0.13764\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 118ms/step - loss: 0.1406 - mae: 0.2259 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 9.7656e-07\n",
      "Epoch 75/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.1406 - mae: 0.2259\n",
      "Epoch 75: val_loss did not improve from 0.13764\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 117ms/step - loss: 0.1406 - mae: 0.2259 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 4.8828e-07\n",
      "Epoch 76/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.1405 - mae: 0.2259\n",
      "Epoch 76: val_loss improved from 0.13764 to 0.13764, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 122ms/step - loss: 0.1406 - mae: 0.2259 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 4.8828e-07\n",
      "Epoch 77/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.1407 - mae: 0.2260\n",
      "Epoch 77: val_loss did not improve from 0.13764\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 118ms/step - loss: 0.1406 - mae: 0.2259 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 4.8828e-07\n",
      "Epoch 78/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.1406 - mae: 0.2259\n",
      "Epoch 78: val_loss improved from 0.13764 to 0.13764, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\\autoencoder_best.keras\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 123ms/step - loss: 0.1406 - mae: 0.2259 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 4.8828e-07\n",
      "Epoch 79/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.1402 - mae: 0.2254\n",
      "Epoch 79: val_loss did not improve from 0.13764\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 118ms/step - loss: 0.1406 - mae: 0.2259 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 4.8828e-07\n",
      "Epoch 80/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.1403 - mae: 0.2256\n",
      "Epoch 80: val_loss did not improve from 0.13764\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 118ms/step - loss: 0.1406 - mae: 0.2259 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 2.4414e-07\n",
      "Epoch 81/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.1405 - mae: 0.2259\n",
      "Epoch 81: val_loss did not improve from 0.13764\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 118ms/step - loss: 0.1406 - mae: 0.2259 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 2.4414e-07\n",
      "Epoch 82/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.1409 - mae: 0.2262\n",
      "Epoch 82: val_loss did not improve from 0.13764\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 117ms/step - loss: 0.1406 - mae: 0.2259 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 2.4414e-07\n",
      "Epoch 83/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.1404 - mae: 0.2255\n",
      "Epoch 83: val_loss did not improve from 0.13764\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 118ms/step - loss: 0.1406 - mae: 0.2259 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 2.4414e-07\n",
      "Epoch 84/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.1406 - mae: 0.2259\n",
      "Epoch 84: val_loss did not improve from 0.13764\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 118ms/step - loss: 0.1406 - mae: 0.2259 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 2.4414e-07\n",
      "Epoch 85/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.1404 - mae: 0.2256\n",
      "Epoch 85: val_loss did not improve from 0.13764\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 118ms/step - loss: 0.1406 - mae: 0.2259 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 1.2207e-07\n",
      "Epoch 86/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.1400 - mae: 0.2253\n",
      "Epoch 86: val_loss did not improve from 0.13764\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 119ms/step - loss: 0.1406 - mae: 0.2259 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 1.2207e-07\n",
      "Epoch 87/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.1410 - mae: 0.2264\n",
      "Epoch 87: val_loss did not improve from 0.13764\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 118ms/step - loss: 0.1406 - mae: 0.2259 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 1.2207e-07\n",
      "Epoch 88/100\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.1409 - mae: 0.2262\n",
      "Epoch 88: val_loss did not improve from 0.13764\n",
      "\u001b[1m2460/2460\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 118ms/step - loss: 0.1406 - mae: 0.2259 - val_loss: 0.1376 - val_mae: 0.2233 - learning_rate: 1.2207e-07\n",
      "Epoch 88: early stopping\n",
      "Restoring model weights from the end of the best epoch: 78.\n",
      "\n",
      "‚úÖ Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Compile and train autoencoder\n",
    "print(\"=\"*80)\n",
    "print(\"COMPILING AND TRAINING AUTOENCODER (PHASE 2a)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Compile\n",
    "autoencoder_2a.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "# Setup callbacks\n",
    "phase2a_dir = RESULTS_DIR / 'phase2a'\n",
    "phase2a_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "checkpoint_path = str(phase2a_dir / 'autoencoder_best.keras')\n",
    "\n",
    "callbacks_list = [\n",
    "    callbacks.ModelCheckpoint(\n",
    "        checkpoint_path,\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train\n",
    "print(\"\\nStarting training...\")\n",
    "history_2a = autoencoder_2a.fit(\n",
    "    X_train, X_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, X_val),\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3c57932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving models...\n",
      "‚úÖ All files saved to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2a\n"
     ]
    }
   ],
   "source": [
    "# Save models and history\n",
    "print(\"Saving models...\")\n",
    "\n",
    "autoencoder_2a.save(phase2a_dir / 'autoencoder_final.keras')\n",
    "encoder_2a.save(phase2a_dir / 'encoder.keras')\n",
    "decoder_2a.save(phase2a_dir / 'decoder.keras')\n",
    "\n",
    "# Save training history\n",
    "history_dict = {\n",
    "    'loss': [float(x) for x in history_2a.history['loss']],\n",
    "    'val_loss': [float(x) for x in history_2a.history['val_loss']],\n",
    "    'mae': [float(x) for x in history_2a.history.get('mae', [])],\n",
    "    'val_mae': [float(x) for x in history_2a.history.get('val_mae', [])]\n",
    "}\n",
    "\n",
    "with open(phase2a_dir / 'training_history.json', 'w') as f:\n",
    "    json.dump(history_dict, f, indent=2)\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    'dataset': 'NIH_Full',\n",
    "    'train_samples': len(X_train),\n",
    "    'val_samples': len(X_val),\n",
    "    'epochs_trained': len(history_2a.history['loss']),\n",
    "    'best_val_loss': float(min(history_2a.history['val_loss'])),\n",
    "    'architecture': 'ConvAutoencoder',\n",
    "    'latent_dim': 256,\n",
    "    'backend': keras.backend.backend()\n",
    "}\n",
    "\n",
    "with open(phase2a_dir / 'metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ All files saved to {phase2a_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df5b6285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training curves saved\n"
     ]
    }
   ],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history_2a.history['loss'], label='Train Loss', linewidth=2)\n",
    "axes[0].plot(history_2a.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('MSE Loss', fontsize=12)\n",
    "axes[0].set_title('Phase 2a: Training Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# MAE\n",
    "if 'mae' in history_2a.history:\n",
    "    axes[1].plot(history_2a.history['mae'], label='Train MAE', linewidth=2)\n",
    "    axes[1].plot(history_2a.history['val_mae'], label='Val MAE', linewidth=2)\n",
    "    axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[1].set_ylabel('MAE', fontsize=12)\n",
    "    axes[1].set_title('Phase 2a: Mean Absolute Error', fontsize=14, fontweight='bold')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(phase2a_dir / 'training_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Training curves saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a8260e",
   "metadata": {},
   "source": [
    "## Phase 2b: NIH_Normal Autoencoder\n",
    "\n",
    "**Data:** Only normal NIH images  \n",
    "**Purpose:** Learn \"normal\" appearance to detect distribution shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dfb5be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PHASE 2b: NIH_NORMAL AUTOENCODER\n",
      "================================================================================\n",
      "‚úÖ Training (normals): (42270, 224, 224, 1)\n",
      "‚úÖ Validation (normals): (9189, 224, 224, 1)\n",
      "\n",
      "Starting training (normals only)...\n",
      "Epoch 1/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.1804 - mae: 0.3099\n",
      "Epoch 1: val_loss improved from None to 0.13756, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 109ms/step - loss: 0.1554 - mae: 0.2745 - val_loss: 0.1376 - val_mae: 0.2361 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.1398 - mae: 0.2372\n",
      "Epoch 2: val_loss improved from 0.13756 to 0.13589, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 107ms/step - loss: 0.1394 - mae: 0.2357 - val_loss: 0.1359 - val_mae: 0.2297 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.1382 - mae: 0.2321\n",
      "Epoch 3: val_loss improved from 0.13589 to 0.13555, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 110ms/step - loss: 0.1385 - mae: 0.2320 - val_loss: 0.1355 - val_mae: 0.2285 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.1385 - mae: 0.2311\n",
      "Epoch 4: val_loss improved from 0.13555 to 0.13514, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 109ms/step - loss: 0.1381 - mae: 0.2304 - val_loss: 0.1351 - val_mae: 0.2266 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.1375 - mae: 0.2291\n",
      "Epoch 5: val_loss improved from 0.13514 to 0.13491, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 109ms/step - loss: 0.1379 - mae: 0.2292 - val_loss: 0.1349 - val_mae: 0.2260 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.1382 - mae: 0.2290\n",
      "Epoch 6: val_loss improved from 0.13491 to 0.13487, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 108ms/step - loss: 0.1377 - mae: 0.2284 - val_loss: 0.1349 - val_mae: 0.2256 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.1373 - mae: 0.2277\n",
      "Epoch 7: val_loss improved from 0.13487 to 0.13469, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 109ms/step - loss: 0.1376 - mae: 0.2280 - val_loss: 0.1347 - val_mae: 0.2246 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.1372 - mae: 0.2269\n",
      "Epoch 8: val_loss did not improve from 0.13469\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 101ms/step - loss: 0.1375 - mae: 0.2274 - val_loss: 0.1348 - val_mae: 0.2250 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.1368 - mae: 0.2266\n",
      "Epoch 9: val_loss improved from 0.13469 to 0.13461, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 109ms/step - loss: 0.1374 - mae: 0.2271 - val_loss: 0.1346 - val_mae: 0.2240 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.1379 - mae: 0.2272\n",
      "Epoch 10: val_loss improved from 0.13461 to 0.13451, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 109ms/step - loss: 0.1373 - mae: 0.2267 - val_loss: 0.1345 - val_mae: 0.2236 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.1371 - mae: 0.2263\n",
      "Epoch 11: val_loss did not improve from 0.13451\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 101ms/step - loss: 0.1373 - mae: 0.2264 - val_loss: 0.1345 - val_mae: 0.2241 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.1369 - mae: 0.2257\n",
      "Epoch 12: val_loss improved from 0.13451 to 0.13442, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 108ms/step - loss: 0.1372 - mae: 0.2261 - val_loss: 0.1344 - val_mae: 0.2232 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.1371 - mae: 0.2259\n",
      "Epoch 13: val_loss did not improve from 0.13442\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 100ms/step - loss: 0.1372 - mae: 0.2259 - val_loss: 0.1345 - val_mae: 0.2236 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.1369 - mae: 0.2255\n",
      "Epoch 14: val_loss improved from 0.13442 to 0.13436, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 112ms/step - loss: 0.1371 - mae: 0.2257 - val_loss: 0.1344 - val_mae: 0.2229 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.1373 - mae: 0.2258\n",
      "Epoch 15: val_loss did not improve from 0.13436\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 103ms/step - loss: 0.1371 - mae: 0.2255 - val_loss: 0.1344 - val_mae: 0.2228 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.1368 - mae: 0.2252\n",
      "Epoch 16: val_loss improved from 0.13436 to 0.13433, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 110ms/step - loss: 0.1371 - mae: 0.2254 - val_loss: 0.1343 - val_mae: 0.2229 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.1375 - mae: 0.2258\n",
      "Epoch 17: val_loss did not improve from 0.13433\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 103ms/step - loss: 0.1370 - mae: 0.2251 - val_loss: 0.1344 - val_mae: 0.2230 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.1369 - mae: 0.2249\n",
      "Epoch 18: val_loss improved from 0.13433 to 0.13424, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 111ms/step - loss: 0.1370 - mae: 0.2250 - val_loss: 0.1342 - val_mae: 0.2222 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.1369 - mae: 0.2248\n",
      "Epoch 19: val_loss did not improve from 0.13424\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 103ms/step - loss: 0.1370 - mae: 0.2249 - val_loss: 0.1343 - val_mae: 0.2223 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.1368 - mae: 0.2245\n",
      "Epoch 20: val_loss did not improve from 0.13424\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 105ms/step - loss: 0.1369 - mae: 0.2247 - val_loss: 0.1343 - val_mae: 0.2229 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.1372 - mae: 0.2248\n",
      "Epoch 21: val_loss improved from 0.13424 to 0.13420, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 262ms/step - loss: 0.1369 - mae: 0.2246 - val_loss: 0.1342 - val_mae: 0.2219 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.1364 - mae: 0.2237\n",
      "Epoch 22: val_loss improved from 0.13420 to 0.13418, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 213ms/step - loss: 0.1369 - mae: 0.2244 - val_loss: 0.1342 - val_mae: 0.2219 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.1371 - mae: 0.2247\n",
      "Epoch 23: val_loss improved from 0.13418 to 0.13416, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 109ms/step - loss: 0.1369 - mae: 0.2243 - val_loss: 0.1342 - val_mae: 0.2217 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.1369 - mae: 0.2236\n",
      "Epoch 24: val_loss improved from 0.13416 to 0.13403, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 108ms/step - loss: 0.1367 - mae: 0.2233 - val_loss: 0.1340 - val_mae: 0.2210 - learning_rate: 5.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.1366 - mae: 0.2230\n",
      "Epoch 25: val_loss improved from 0.13403 to 0.13401, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 108ms/step - loss: 0.1367 - mae: 0.2232 - val_loss: 0.1340 - val_mae: 0.2209 - learning_rate: 5.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.1363 - mae: 0.2228\n",
      "Epoch 26: val_loss improved from 0.13401 to 0.13400, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 109ms/step - loss: 0.1366 - mae: 0.2231 - val_loss: 0.1340 - val_mae: 0.2208 - learning_rate: 5.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.1368 - mae: 0.2232\n",
      "Epoch 27: val_loss improved from 0.13400 to 0.13399, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 109ms/step - loss: 0.1366 - mae: 0.2230 - val_loss: 0.1340 - val_mae: 0.2207 - learning_rate: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.1366 - mae: 0.2229\n",
      "Epoch 28: val_loss improved from 0.13399 to 0.13398, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 109ms/step - loss: 0.1366 - mae: 0.2230 - val_loss: 0.1340 - val_mae: 0.2207 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.1369 - mae: 0.2232\n",
      "Epoch 29: val_loss improved from 0.13398 to 0.13397, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 109ms/step - loss: 0.1366 - mae: 0.2229 - val_loss: 0.1340 - val_mae: 0.2206 - learning_rate: 5.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.1362 - mae: 0.2220\n",
      "Epoch 30: val_loss improved from 0.13397 to 0.13392, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 107ms/step - loss: 0.1365 - mae: 0.2224 - val_loss: 0.1339 - val_mae: 0.2203 - learning_rate: 2.5000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.1368 - mae: 0.2227\n",
      "Epoch 31: val_loss improved from 0.13392 to 0.13391, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 111ms/step - loss: 0.1365 - mae: 0.2224 - val_loss: 0.1339 - val_mae: 0.2203 - learning_rate: 2.5000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.1368 - mae: 0.2226\n",
      "Epoch 32: val_loss improved from 0.13391 to 0.13391, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 109ms/step - loss: 0.1365 - mae: 0.2223 - val_loss: 0.1339 - val_mae: 0.2202 - learning_rate: 2.5000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.1366 - mae: 0.2224\n",
      "Epoch 33: val_loss improved from 0.13391 to 0.13390, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 108ms/step - loss: 0.1365 - mae: 0.2223 - val_loss: 0.1339 - val_mae: 0.2202 - learning_rate: 2.5000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.1364 - mae: 0.2220\n",
      "Epoch 34: val_loss did not improve from 0.13390\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 100ms/step - loss: 0.1365 - mae: 0.2223 - val_loss: 0.1339 - val_mae: 0.2202 - learning_rate: 2.5000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.1369 - mae: 0.2228\n",
      "Epoch 35: val_loss improved from 0.13390 to 0.13389, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 107ms/step - loss: 0.1365 - mae: 0.2222 - val_loss: 0.1339 - val_mae: 0.2202 - learning_rate: 2.5000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.1360 - mae: 0.2213\n",
      "Epoch 36: val_loss improved from 0.13389 to 0.13388, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 108ms/step - loss: 0.1365 - mae: 0.2220 - val_loss: 0.1339 - val_mae: 0.2200 - learning_rate: 1.2500e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.1367 - mae: 0.2223\n",
      "Epoch 37: val_loss did not improve from 0.13388\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 99ms/step - loss: 0.1364 - mae: 0.2220 - val_loss: 0.1339 - val_mae: 0.2200 - learning_rate: 1.2500e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1363 - mae: 0.2217\n",
      "Epoch 38: val_loss improved from 0.13388 to 0.13387, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 106ms/step - loss: 0.1364 - mae: 0.2220 - val_loss: 0.1339 - val_mae: 0.2200 - learning_rate: 1.2500e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.1378 - mae: 0.2235\n",
      "Epoch 39: val_loss did not improve from 0.13387\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 101ms/step - loss: 0.1364 - mae: 0.2220 - val_loss: 0.1339 - val_mae: 0.2199 - learning_rate: 1.2500e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.1363 - mae: 0.2218\n",
      "Epoch 40: val_loss improved from 0.13387 to 0.13387, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 107ms/step - loss: 0.1364 - mae: 0.2219 - val_loss: 0.1339 - val_mae: 0.2200 - learning_rate: 1.2500e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.1367 - mae: 0.2221\n",
      "Epoch 41: val_loss improved from 0.13387 to 0.13386, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 108ms/step - loss: 0.1364 - mae: 0.2218 - val_loss: 0.1339 - val_mae: 0.2199 - learning_rate: 6.2500e-05\n",
      "Epoch 42/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.1362 - mae: 0.2215\n",
      "Epoch 42: val_loss improved from 0.13386 to 0.13386, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 106ms/step - loss: 0.1364 - mae: 0.2218 - val_loss: 0.1339 - val_mae: 0.2199 - learning_rate: 6.2500e-05\n",
      "Epoch 43/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1364 - mae: 0.2218\n",
      "Epoch 43: val_loss did not improve from 0.13386\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 98ms/step - loss: 0.1364 - mae: 0.2218 - val_loss: 0.1339 - val_mae: 0.2199 - learning_rate: 6.2500e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1364 - mae: 0.2217\n",
      "Epoch 44: val_loss improved from 0.13386 to 0.13386, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 105ms/step - loss: 0.1364 - mae: 0.2218 - val_loss: 0.1339 - val_mae: 0.2199 - learning_rate: 6.2500e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.1360 - mae: 0.2214\n",
      "Epoch 45: val_loss improved from 0.13386 to 0.13386, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 106ms/step - loss: 0.1364 - mae: 0.2218 - val_loss: 0.1339 - val_mae: 0.2199 - learning_rate: 6.2500e-05\n",
      "Epoch 46/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.1358 - mae: 0.2211\n",
      "Epoch 46: val_loss improved from 0.13386 to 0.13385, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 107ms/step - loss: 0.1364 - mae: 0.2217 - val_loss: 0.1339 - val_mae: 0.2198 - learning_rate: 3.1250e-05\n",
      "Epoch 47/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1359 - mae: 0.2210\n",
      "Epoch 47: val_loss did not improve from 0.13385\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 98ms/step - loss: 0.1364 - mae: 0.2217 - val_loss: 0.1339 - val_mae: 0.2198 - learning_rate: 3.1250e-05\n",
      "Epoch 48/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1370 - mae: 0.2225\n",
      "Epoch 48: val_loss did not improve from 0.13385\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 98ms/step - loss: 0.1364 - mae: 0.2217 - val_loss: 0.1339 - val_mae: 0.2198 - learning_rate: 3.1250e-05\n",
      "Epoch 49/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.1361 - mae: 0.2214\n",
      "Epoch 49: val_loss improved from 0.13385 to 0.13385, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 104ms/step - loss: 0.1364 - mae: 0.2217 - val_loss: 0.1339 - val_mae: 0.2198 - learning_rate: 3.1250e-05\n",
      "Epoch 50/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.1368 - mae: 0.2222\n",
      "Epoch 50: val_loss did not improve from 0.13385\n",
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 101ms/step - loss: 0.1364 - mae: 0.2217 - val_loss: 0.1339 - val_mae: 0.2198 - learning_rate: 3.1250e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.1364 - mae: 0.2216\n",
      "Epoch 51: val_loss improved from 0.13385 to 0.13385, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 108ms/step - loss: 0.1364 - mae: 0.2217 - val_loss: 0.1339 - val_mae: 0.2198 - learning_rate: 1.5625e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.1362 - mae: 0.2215\n",
      "Epoch 52: val_loss improved from 0.13385 to 0.13385, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 107ms/step - loss: 0.1364 - mae: 0.2217 - val_loss: 0.1339 - val_mae: 0.2198 - learning_rate: 1.5625e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.1366 - mae: 0.2219\n",
      "Epoch 53: val_loss improved from 0.13385 to 0.13385, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 106ms/step - loss: 0.1364 - mae: 0.2217 - val_loss: 0.1339 - val_mae: 0.2198 - learning_rate: 1.5625e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.1365 - mae: 0.2219\n",
      "Epoch 54: val_loss did not improve from 0.13385\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 99ms/step - loss: 0.1364 - mae: 0.2217 - val_loss: 0.1339 - val_mae: 0.2198 - learning_rate: 1.5625e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1369 - mae: 0.2221\n",
      "Epoch 55: val_loss improved from 0.13385 to 0.13385, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 105ms/step - loss: 0.1364 - mae: 0.2217 - val_loss: 0.1339 - val_mae: 0.2198 - learning_rate: 1.5625e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1367 - mae: 0.2221\n",
      "Epoch 56: val_loss improved from 0.13385 to 0.13385, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 106ms/step - loss: 0.1364 - mae: 0.2217 - val_loss: 0.1339 - val_mae: 0.2198 - learning_rate: 7.8125e-06\n",
      "Epoch 57/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1357 - mae: 0.2210\n",
      "Epoch 57: val_loss improved from 0.13385 to 0.13385, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 106ms/step - loss: 0.1364 - mae: 0.2217 - val_loss: 0.1339 - val_mae: 0.2198 - learning_rate: 7.8125e-06\n",
      "Epoch 58/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1361 - mae: 0.2213\n",
      "Epoch 58: val_loss improved from 0.13385 to 0.13385, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 105ms/step - loss: 0.1364 - mae: 0.2217 - val_loss: 0.1339 - val_mae: 0.2198 - learning_rate: 7.8125e-06\n",
      "Epoch 59/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1374 - mae: 0.2229\n",
      "Epoch 59: val_loss did not improve from 0.13385\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 98ms/step - loss: 0.1364 - mae: 0.2217 - val_loss: 0.1339 - val_mae: 0.2198 - learning_rate: 7.8125e-06\n",
      "Epoch 60/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.1366 - mae: 0.2219\n",
      "Epoch 60: val_loss did not improve from 0.13385\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 97ms/step - loss: 0.1364 - mae: 0.2217 - val_loss: 0.1339 - val_mae: 0.2198 - learning_rate: 7.8125e-06\n",
      "Epoch 61/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.1365 - mae: 0.2219\n",
      "Epoch 61: val_loss improved from 0.13385 to 0.13385, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 105ms/step - loss: 0.1364 - mae: 0.2217 - val_loss: 0.1339 - val_mae: 0.2198 - learning_rate: 3.9063e-06\n",
      "Epoch 62/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.1366 - mae: 0.2220\n",
      "Epoch 62: val_loss did not improve from 0.13385\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 96ms/step - loss: 0.1364 - mae: 0.2217 - val_loss: 0.1339 - val_mae: 0.2198 - learning_rate: 3.9063e-06\n",
      "Epoch 63/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.1362 - mae: 0.2214\n",
      "Epoch 63: val_loss did not improve from 0.13385\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 97ms/step - loss: 0.1364 - mae: 0.2217 - val_loss: 0.1339 - val_mae: 0.2198 - learning_rate: 3.9063e-06\n",
      "Epoch 64/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1363 - mae: 0.2217\n",
      "Epoch 64: val_loss did not improve from 0.13385\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 97ms/step - loss: 0.1364 - mae: 0.2216 - val_loss: 0.1339 - val_mae: 0.2198 - learning_rate: 3.9063e-06\n",
      "Epoch 65/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.1362 - mae: 0.2214\n",
      "Epoch 65: val_loss did not improve from 0.13385\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 95ms/step - loss: 0.1364 - mae: 0.2216 - val_loss: 0.1339 - val_mae: 0.2198 - learning_rate: 3.9063e-06\n",
      "Epoch 66/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.1359 - mae: 0.2211\n",
      "Epoch 66: val_loss improved from 0.13385 to 0.13385, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 105ms/step - loss: 0.1364 - mae: 0.2216 - val_loss: 0.1339 - val_mae: 0.2198 - learning_rate: 1.9531e-06\n",
      "Epoch 67/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.1368 - mae: 0.2222\n",
      "Epoch 67: val_loss did not improve from 0.13385\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 99ms/step - loss: 0.1364 - mae: 0.2216 - val_loss: 0.1339 - val_mae: 0.2198 - learning_rate: 1.9531e-06\n",
      "Epoch 68/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1366 - mae: 0.2220\n",
      "Epoch 68: val_loss improved from 0.13385 to 0.13385, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 106ms/step - loss: 0.1364 - mae: 0.2216 - val_loss: 0.1338 - val_mae: 0.2198 - learning_rate: 1.9531e-06\n",
      "Epoch 69/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1366 - mae: 0.2219\n",
      "Epoch 69: val_loss did not improve from 0.13385\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 98ms/step - loss: 0.1364 - mae: 0.2216 - val_loss: 0.1339 - val_mae: 0.2198 - learning_rate: 1.9531e-06\n",
      "Epoch 70/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.1370 - mae: 0.2222\n",
      "Epoch 70: val_loss did not improve from 0.13385\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 99ms/step - loss: 0.1364 - mae: 0.2216 - val_loss: 0.1339 - val_mae: 0.2198 - learning_rate: 1.9531e-06\n",
      "Epoch 71/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.1363 - mae: 0.2216\n",
      "Epoch 71: val_loss improved from 0.13385 to 0.13385, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 108ms/step - loss: 0.1364 - mae: 0.2216 - val_loss: 0.1338 - val_mae: 0.2198 - learning_rate: 9.7656e-07\n",
      "Epoch 72/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.1358 - mae: 0.2209\n",
      "Epoch 72: val_loss did not improve from 0.13385\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 102ms/step - loss: 0.1364 - mae: 0.2216 - val_loss: 0.1339 - val_mae: 0.2198 - learning_rate: 9.7656e-07\n",
      "Epoch 73/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.1370 - mae: 0.2222\n",
      "Epoch 73: val_loss did not improve from 0.13385\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 100ms/step - loss: 0.1364 - mae: 0.2216 - val_loss: 0.1338 - val_mae: 0.2198 - learning_rate: 9.7656e-07\n",
      "Epoch 74/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1364 - mae: 0.2217\n",
      "Epoch 74: val_loss did not improve from 0.13385\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 98ms/step - loss: 0.1364 - mae: 0.2216 - val_loss: 0.1338 - val_mae: 0.2198 - learning_rate: 9.7656e-07\n",
      "Epoch 75/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1360 - mae: 0.2211\n",
      "Epoch 75: val_loss improved from 0.13385 to 0.13385, saving model to F:\\CAS AML\\M3_project\\downloads\\Results\\phase2b\\autoencoder_best.keras\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 105ms/step - loss: 0.1364 - mae: 0.2216 - val_loss: 0.1338 - val_mae: 0.2198 - learning_rate: 9.7656e-07\n",
      "Epoch 76/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.1358 - mae: 0.2210\n",
      "Epoch 76: val_loss did not improve from 0.13385\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 99ms/step - loss: 0.1364 - mae: 0.2216 - val_loss: 0.1338 - val_mae: 0.2198 - learning_rate: 4.8828e-07\n",
      "Epoch 77/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1360 - mae: 0.2213\n",
      "Epoch 77: val_loss did not improve from 0.13385\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 98ms/step - loss: 0.1364 - mae: 0.2216 - val_loss: 0.1338 - val_mae: 0.2198 - learning_rate: 4.8828e-07\n",
      "Epoch 78/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1367 - mae: 0.2220\n",
      "Epoch 78: val_loss did not improve from 0.13385\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 98ms/step - loss: 0.1364 - mae: 0.2216 - val_loss: 0.1339 - val_mae: 0.2198 - learning_rate: 4.8828e-07\n",
      "Epoch 79/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.1363 - mae: 0.2217\n",
      "Epoch 79: val_loss did not improve from 0.13385\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 97ms/step - loss: 0.1364 - mae: 0.2216 - val_loss: 0.1338 - val_mae: 0.2198 - learning_rate: 4.8828e-07\n",
      "Epoch 80/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.1368 - mae: 0.2219\n",
      "Epoch 80: val_loss did not improve from 0.13385\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 99ms/step - loss: 0.1364 - mae: 0.2216 - val_loss: 0.1338 - val_mae: 0.2198 - learning_rate: 4.8828e-07\n",
      "Epoch 81/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1361 - mae: 0.2211\n",
      "Epoch 81: val_loss did not improve from 0.13385\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 98ms/step - loss: 0.1364 - mae: 0.2216 - val_loss: 0.1338 - val_mae: 0.2198 - learning_rate: 2.4414e-07\n",
      "Epoch 82/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.1361 - mae: 0.2213\n",
      "Epoch 82: val_loss did not improve from 0.13385\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 96ms/step - loss: 0.1364 - mae: 0.2216 - val_loss: 0.1338 - val_mae: 0.2198 - learning_rate: 2.4414e-07\n",
      "Epoch 83/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.1366 - mae: 0.2220\n",
      "Epoch 83: val_loss did not improve from 0.13385\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 96ms/step - loss: 0.1364 - mae: 0.2216 - val_loss: 0.1339 - val_mae: 0.2198 - learning_rate: 2.4414e-07\n",
      "Epoch 84/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1364 - mae: 0.2218\n",
      "Epoch 84: val_loss did not improve from 0.13385\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 97ms/step - loss: 0.1364 - mae: 0.2216 - val_loss: 0.1338 - val_mae: 0.2198 - learning_rate: 2.4414e-07\n",
      "Epoch 85/100\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1362 - mae: 0.2214\n",
      "Epoch 85: val_loss did not improve from 0.13385\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 97ms/step - loss: 0.1364 - mae: 0.2216 - val_loss: 0.1338 - val_mae: 0.2198 - learning_rate: 2.4414e-07\n",
      "Epoch 85: early stopping\n",
      "Restoring model weights from the end of the best epoch: 75.\n",
      "\n",
      "‚úÖ Phase 2b complete!\n"
     ]
    }
   ],
   "source": [
    "# Build and train Phase 2b autoencoder (normals only)\n",
    "# [Similar code to Phase 2a, but using *_normals.h5 files]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PHASE 2b: NIH_NORMAL AUTOENCODER\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load normal images only\n",
    "train_normal_path = DATA_DIR / 'nih' / 'train_normals.h5'\n",
    "val_normal_path = DATA_DIR / 'nih' / 'val_normals.h5'\n",
    "\n",
    "with h5py.File(train_normal_path, 'r') as f:\n",
    "    X_train_normal = f['images'][:]\n",
    "    print(f\"‚úÖ Training (normals): {X_train_normal.shape}\")\n",
    "\n",
    "with h5py.File(val_normal_path, 'r') as f:\n",
    "    X_val_normal = f['images'][:]\n",
    "    print(f\"‚úÖ Validation (normals): {X_val_normal.shape}\")\n",
    "\n",
    "# Normalize\n",
    "if X_train_normal.max() > 1.0:\n",
    "    X_train_normal = X_train_normal / 255.0\n",
    "    X_val_normal = X_val_normal / 255.0\n",
    "\n",
    "# Build new autoencoder\n",
    "encoder_2b, decoder_2b, autoencoder_2b = build_autoencoder()\n",
    "\n",
    "# Compile\n",
    "autoencoder_2b.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "# Setup callbacks\n",
    "phase2b_dir = RESULTS_DIR / 'phase2b'\n",
    "phase2b_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "callbacks_2b = [\n",
    "    callbacks.ModelCheckpoint(\n",
    "        str(phase2b_dir / 'autoencoder_best.keras'),\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train\n",
    "print(\"\\nStarting training (normals only)...\")\n",
    "history_2b = autoencoder_2b.fit(\n",
    "    X_train_normal, X_train_normal,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val_normal, X_val_normal),\n",
    "    callbacks=callbacks_2b,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save models\n",
    "autoencoder_2b.save(phase2b_dir / 'autoencoder_final.keras')\n",
    "encoder_2b.save(phase2b_dir / 'encoder.keras')\n",
    "decoder_2b.save(phase2b_dir / 'decoder.keras')\n",
    "\n",
    "print(\"\\n‚úÖ Phase 2b complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ae7f9f",
   "metadata": {},
   "source": [
    "---\n",
    "# üìÅ Phase 3: Reconstruction Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ba845f",
   "metadata": {},
   "source": [
    "## Phase 3a: NIH_Full Autoencoder on All Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1440515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PHASE 3a: RECONSTRUCTION ERROR ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "üìä Processing NIH...\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.11 GiB for an array with shape (16655, 224, 224, 1) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m test_path = DATA_DIR / dataset_name / \u001b[33m'\u001b[39m\u001b[33mtest.h5\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m h5py.File(test_path, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     X_test = \u001b[43mf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mimages\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m X_test.max() > \u001b[32m1.0\u001b[39m:\n\u001b[32m     26\u001b[39m     X_test = X_test / \u001b[32m255.0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:54\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:55\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\h5py\\_hl\\dataset.py:840\u001b[39m, in \u001b[36mDataset.__getitem__\u001b[39m\u001b[34m(self, args, new_dtype)\u001b[39m\n\u001b[32m    838\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fast_read_ok \u001b[38;5;129;01mand\u001b[39;00m (new_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    839\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m840\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fast_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    841\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    842\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall back to Python read pathway below\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_selector.pyx:367\u001b[39m, in \u001b[36mh5py._selector.Reader.read\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_selector.pyx:341\u001b[39m, in \u001b[36mh5py._selector.Reader.make_array\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 3.11 GiB for an array with shape (16655, 224, 224, 1) and data type float32"
     ]
    }
   ],
   "source": [
    "# Compute reconstruction errors\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"  # hide GPU from PyTorch/Keras\n",
    "import torch\n",
    "torch.set_default_device(\"cpu\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PHASE 3a: RECONSTRUCTION ERROR ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load best autoencoder\n",
    "autoencoder_2a_best = keras.models.load_model(phase2a_dir / 'autoencoder_best.keras')\n",
    "\n",
    "results_3a = {}\n",
    "\n",
    "for dataset_name in ['nih', 'pediatric', 'chexpert']:\n",
    "    print(f\"\\nüìä Processing {dataset_name.upper()}...\")\n",
    "    \n",
    "    # Load test images\n",
    "    test_path = DATA_DIR / dataset_name / 'test.h5'\n",
    "    \n",
    "    with h5py.File(test_path, 'r') as f:\n",
    "        X_test = f['images'][:]\n",
    "    \n",
    "    if X_test.max() > 1.0:\n",
    "        X_test = X_test / 255.0\n",
    "    \n",
    "    # Reconstruct\n",
    "    X_reconstructed = autoencoder_2a_best.predict(X_test, batch_size=32, verbose=0)\n",
    "    \n",
    "    # Compute per-image MSE\n",
    "    errors = np.mean((X_test - X_reconstructed) ** 2, axis=(1, 2, 3))\n",
    "    \n",
    "    results_3a[dataset_name] = {\n",
    "        'mean': float(errors.mean()),\n",
    "        'std': float(errors.std()),\n",
    "        'median': float(np.median(errors)),\n",
    "        'min': float(errors.min()),\n",
    "        'max': float(errors.max()),\n",
    "        'errors': errors\n",
    "    }\n",
    "    \n",
    "    print(f\"   Mean error: {errors.mean():.6f}\")\n",
    "    print(f\"   Std:        {errors.std():.6f}\")\n",
    "    print(f\"   Range:      [{errors.min():.6f}, {errors.max():.6f}]\")\n",
    "\n",
    "# Save results\n",
    "phase3a_dir = RESULTS_DIR / 'phase3a'\n",
    "phase3a_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "summary_3a = pd.DataFrame([\n",
    "    {\n",
    "        'Dataset': name.upper(),\n",
    "        'Mean_Error': results_3a[name]['mean'],\n",
    "        'Std_Error': results_3a[name]['std'],\n",
    "        'Median_Error': results_3a[name]['median']\n",
    "    }\n",
    "    for name in results_3a.keys()\n",
    "])\n",
    "\n",
    "summary_3a.to_csv(phase3a_dir / 'phase3a_summary.csv', index=False)\n",
    "\n",
    "with open(phase3a_dir / 'phase3a_statistics.json', 'w') as f:\n",
    "    json.dump({k: {kk: vv for kk, vv in v.items() if kk != 'errors'} \n",
    "               for k, v in results_3a.items()}, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ Results saved to {phase3a_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac39967e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize reconstruction errors\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "dataset_order = ['nih', 'pediatric', 'chexpert']\n",
    "means = [results_3a[d]['mean'] for d in dataset_order]\n",
    "labels = [d.upper() for d in dataset_order]\n",
    "\n",
    "bars = ax.bar(labels, means, color=['#4ECDC4', '#FF6B6B', '#45B7D1'], alpha=0.8, edgecolor='black')\n",
    "\n",
    "for bar, val in zip(bars, means):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{val:.6f}',\n",
    "            ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "ax.set_ylabel('Mean Reconstruction Error (MSE)', fontsize=14, fontweight='bold')\n",
    "ax.set_title('Phase 3a: Reconstruction Error by Dataset', fontsize=16, fontweight='bold', pad=20)\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(phase3a_dir / 'phase3a_reconstruction_errors.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Visualization saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72833e8a",
   "metadata": {},
   "source": [
    "---\n",
    "# üìÅ Phase 4: Classifier Training & Evaluation\n",
    "\n",
    "**Model:** DenseNet121-based binary classifier (Normal vs Abnormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a32459d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building classifier...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m29084464/29084464\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"chest_xray_classifier\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"chest_xray_classifier\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ densenet121 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           ‚îÇ     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,037,504</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            ‚îÇ       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ densenet121 (\u001b[38;5;33mFunctional\u001b[0m)        ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           ‚îÇ     \u001b[38;5;34m7,037,504\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense (\u001b[38;5;33mDense\u001b[0m)                   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            ‚îÇ       \u001b[38;5;34m262,400\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout (\u001b[38;5;33mDropout\u001b[0m)               ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              ‚îÇ           \u001b[38;5;34m257\u001b[0m ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,300,161</span> (27.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,300,161\u001b[0m (27.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,411,841</span> (24.46 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,411,841\u001b[0m (24.46 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">888,320</span> (3.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m888,320\u001b[0m (3.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build classifier (DenseNet121 base)\n",
    "from keras.applications import DenseNet121\n",
    "\n",
    "def build_classifier(input_shape=(224, 224, 3)):\n",
    "    \"\"\"\n",
    "    Build binary classifier using DenseNet121 backbone\n",
    "    \"\"\"\n",
    "    base_model = DenseNet121(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=input_shape,\n",
    "        pooling='avg'\n",
    "    )\n",
    "    \n",
    "    # Freeze early layers\n",
    "    for layer in base_model.layers[:100]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Build classifier head\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = models.Model(inputs, outputs, name='chest_xray_classifier')\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"Building classifier...\")\n",
    "classifier = build_classifier()\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78de74fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOADING NIH DATA FOR CLASSIFIER TRAINING\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 14.7 GiB for an array with shape (78708, 224, 224, 1) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Load train/val/test\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m h5py.File(DATA_DIR / \u001b[33m'\u001b[39m\u001b[33mnih\u001b[39m\u001b[33m'\u001b[39m / \u001b[33m'\u001b[39m\u001b[33mtrain.h5\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     X_train_clf = \u001b[43mf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mimages\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      9\u001b[39m     y_train_clf = f[\u001b[33m'\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m'\u001b[39m][:, \u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# Column 0 = 'No Finding' (1=normal, 0=abnormal)\u001b[39;00m\n\u001b[32m     10\u001b[39m     \u001b[38;5;66;03m# Invert labels: 0=normal, 1=abnormal\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:54\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:55\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\h5py\\_hl\\dataset.py:840\u001b[39m, in \u001b[36mDataset.__getitem__\u001b[39m\u001b[34m(self, args, new_dtype)\u001b[39m\n\u001b[32m    838\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fast_read_ok \u001b[38;5;129;01mand\u001b[39;00m (new_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    839\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m840\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fast_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    841\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    842\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall back to Python read pathway below\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_selector.pyx:367\u001b[39m, in \u001b[36mh5py._selector.Reader.read\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_selector.pyx:341\u001b[39m, in \u001b[36mh5py._selector.Reader.make_array\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 14.7 GiB for an array with shape (78708, 224, 224, 1) and data type float32"
     ]
    }
   ],
   "source": [
    "# Load and prepare NIH data for classifier training\n",
    "print(\"=\"*80)\n",
    "print(\"LOADING NIH DATA FOR CLASSIFIER TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load train/val/test\n",
    "with h5py.File(DATA_DIR / 'nih' / 'train.h5', 'r') as f:\n",
    "    X_train_clf = f['images'][:]\n",
    "    y_train_clf = f['labels'][:, 0]  # Column 0 = 'No Finding' (1=normal, 0=abnormal)\n",
    "    # Invert labels: 0=normal, 1=abnormal\n",
    "    y_train_clf = 1 - y_train_clf\n",
    "\n",
    "with h5py.File(DATA_DIR / 'nih' / 'val.h5', 'r') as f:\n",
    "    X_val_clf = f['images'][:]\n",
    "    y_val_clf = 1 - f['labels'][:, 0]\n",
    "\n",
    "with h5py.File(DATA_DIR / 'nih' / 'test.h5', 'r') as f:\n",
    "    X_test_clf = f['images'][:]\n",
    "    y_test_clf = 1 - f['labels'][:, 0]\n",
    "\n",
    "# Normalize\n",
    "if X_train_clf.max() > 1.0:\n",
    "    X_train_clf = X_train_clf / 255.0\n",
    "    X_val_clf = X_val_clf / 255.0\n",
    "    X_test_clf = X_test_clf / 255.0\n",
    "\n",
    "# Convert grayscale to RGB (DenseNet expects 3 channels)\n",
    "X_train_clf = np.repeat(X_train_clf, 3, axis=-1)\n",
    "X_val_clf = np.repeat(X_val_clf, 3, axis=-1)\n",
    "X_test_clf = np.repeat(X_test_clf, 3, axis=-1)\n",
    "\n",
    "print(f\"‚úÖ Training: {X_train_clf.shape}, Labels: {y_train_clf.shape}\")\n",
    "print(f\"‚úÖ Validation: {X_val_clf.shape}, Labels: {y_val_clf.shape}\")\n",
    "print(f\"‚úÖ Test: {X_test_clf.shape}, Labels: {y_test_clf.shape}\")\n",
    "print(f\"\\nClass distribution (train): {np.bincount(y_train_clf.astype(int))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5159a096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and train classifier\n",
    "print(\"=\"*80)\n",
    "print(\"TRAINING CLASSIFIER\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Compute class weights for imbalanced data\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights_array = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_train_clf),\n",
    "    y=y_train_clf\n",
    ")\n",
    "class_weights = {i: class_weights_array[i] for i in range(len(class_weights_array))}\n",
    "\n",
    "print(f\"Class weights: {class_weights}\")\n",
    "\n",
    "# Compile\n",
    "classifier.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "# Setup callbacks\n",
    "phase4_dir = RESULTS_DIR / 'phase4'\n",
    "phase4_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "callbacks_4 = [\n",
    "    callbacks.ModelCheckpoint(\n",
    "        str(phase4_dir / 'classifier_best.keras'),\n",
    "        monitor='val_auc',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_auc',\n",
    "        mode='max',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train\n",
    "print(\"\\nStarting training...\")\n",
    "history_4 = classifier.fit(\n",
    "    X_train_clf, y_train_clf,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val_clf, y_val_clf),\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks_4,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Classifier training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad269de",
   "metadata": {},
   "source": [
    "---\n",
    "# üìÅ Phase 5: Correlation Analysis\n",
    "\n",
    "**Goal:** Test if reconstruction error predicts classifier performance degradation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c865a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlations between reconstruction error and classifier performance\n",
    "print(\"=\"*80)\n",
    "print(\"PHASE 5: CORRELATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load Phase 3 and Phase 4 results\n",
    "# Combine reconstruction errors with classifier metrics\n",
    "# Compute Pearson and Spearman correlations\n",
    "\n",
    "phase5_dir = RESULTS_DIR / 'phase5'\n",
    "phase5_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "correlation_results = {\n",
    "    'reconstruction_error': [],\n",
    "    'balanced_accuracy': [],\n",
    "    'auc': []\n",
    "}\n",
    "\n",
    "# [Add correlation computation code here]\n",
    "\n",
    "print(\"\\n‚úÖ Correlation analysis complete!\")\n",
    "print(f\"Results saved to {phase5_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c09445",
   "metadata": {},
   "source": [
    "---\n",
    "# üìä Summary & Conclusions\n",
    "\n",
    "All phases complete! Check the `Results/` directory for:\n",
    "- Phase 1: Statistical analysis and JS divergence\n",
    "- Phase 2: Trained autoencoders\n",
    "- Phase 3: Reconstruction error analysis\n",
    "- Phase 4: Classifier evaluation\n",
    "- Phase 5: Correlation results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
